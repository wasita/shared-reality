---
title: "Commonality Inference: Paper Analyses"
author: "Reproducibility Code"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
engine: knitr
execute:
  warning: false
  message: false
  cache: true
knitr:
  opts_chunk:
    message: false
    warning: false
    cache: true
---

This document reproduces all behavioral analyses and figures from the paper.

1. **Setup** - Imports and data loading
2. **Manipulation Check** - Stance recognition (Paper p.6)
3. **Generalization Gradient** - Figure 2A + main model (Paper p.8-9)
4. **SR-G Prediction** - Figure 2B + model (Paper p.8)
5. **Distance-Commonality** - Figure 5 SI + model (Paper p.6)
6. **Domain Analysis** - Figure 3 + 42 domain-specific models (Paper p.9)
7. **Prior Calibration** - SI analysis
8. **Sample Description** - Methods section

## 1. Setup

```{r}
#| label: setup
#| include: false
library(reticulate)
use_python(Sys.which("python3"), required = TRUE)
library(lme4)
library(lmerTest)
library(dplyr)
library(tidyr)
library(purrr)
```

```{python}
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr, linregress
from scipy import stats
from statsmodels.stats.multitest import multipletests
import polars as pl
from polars import col, lit

plt.rcParams['font.family'] = 'Helvetica Neue'
sns.set_style('whitegrid')
SAVE_FIGURES = False
```

```{python}
# Find project root
base_dir = Path.cwd().resolve()
while base_dir.name and not (base_dir / 'data').exists():
    base_dir = base_dir.parent
if not (base_dir / 'data').exists():
    raise ValueError('Could not find project root with data directory')

data_dir = base_dir / 'data'
figures_dir = base_dir / 'outputs' / 'figures'
figures_dir.mkdir(parents=True, exist_ok=True)

lowhigh_palette = ['#648FFF', '#DC267F']  # low (blue), high (pink)
print(f'Data directory: {data_dir}')
```

### Load and preprocess data

```{python}
# Load pre-merged behavioral data
df = pl.read_csv(data_dir / 'experiment_data.csv')
df = df.filter(~col('matchedTolerance').is_null())

# Derived variables
df = df.with_columns([
    pl.when(col('matchedTolerance') <= 1).then(lit('shared')).otherwise(lit('opposing')).alias('stance'),
    pl.when(col('matchedQuestion') == col('preChatQuestion')).then(lit('sameQ'))
     .when(col('matchedDomain') == col('preChatDomain')).then(lit('sameD'))
     .otherwise(lit('diffD')).alias('category'),
    (col('postChatResponse') - col('preChatResponse')).abs().alias('distance')
]).rename({'groupId': 'dyadId'})

# Convert to pandas with numeric contrasts
df_pd = df.to_pandas()
df_pd['stance_num'] = df_pd['stance'].map({'opposing': -1, 'shared': 1})
df_pd['category_num'] = df_pd['category'].map({'sameQ': 1, 'sameD': 0, 'diffD': -1}).astype(float)
df_pd['experiment_num'] = df_pd['experiment'].map({'no-chat': -1, 'chat': 1})
df_pd['distance_num'] = df_pd['distance'].map({0: 2, 1: 1, 2: 0, 3: -1, 4: -2})

print(f'Loaded {len(df_pd)} observations from {df_pd["pid"].nunique()} participants')
```

```{python}
#| output: false
# Save main data for R (once)
df_pd.to_csv('/tmp/main_df.csv', index=False)
```

## 2. Manipulation Check

Paper reports: "85% of participants who were assigned to talk about a belief that they actually had in common judged that belief to be shared, compared to only 29%" (p.6)

```{python}
# Filter to observed question only
obs_df = df_pd[df_pd['question'] == df_pd['matchedIdx']]

# Percentages
shared_pct = obs_df[obs_df['stance'] == 'shared']['predictShared'].mean() * 100
opposing_pct = obs_df[obs_df['stance'] == 'opposing']['predictShared'].mean() * 100

print(f'Shared stance: {shared_pct:.0f}% judged belief as shared')
print(f'Opposing stance: {opposing_pct:.0f}% judged belief as shared')
print(f'\nPaper reports: 85% vs 29%')
```

```{python}
#| fig-width: 5
#| fig-height: 4
fig, ax = plt.subplots(figsize=(5, 4))
sns.barplot(data=obs_df, x='stance', y='predictShared', order=['opposing', 'shared'],
            hue='stance', palette=lowhigh_palette, ax=ax)
ax.set_xlabel('Stance Condition')
ax.set_ylabel('Commonality Judgment')
ax.set_ylim([0, 1])
sns.despine()
plt.title('Manipulation Check')
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'manipulation_check.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

## 3. Generalization Gradient (Figure 2A)

Paper reports: stance × question type interaction β = 0.54, 95% CI [0.48, 0.59] (p.8-9)

```{python}
#| fig-cap: "Figure 2A: Generalization gradient"
#| fig-width: 10
#| fig-height: 4
fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)
for i, exp in enumerate(['no-chat', 'chat']):
    ax = axes[i]
    sns.barplot(data=df_pd[df_pd['experiment'] == exp], x='category', y='predictShared',
                order=['sameQ', 'sameD', 'diffD'], hue='stance', hue_order=['opposing', 'shared'],
                palette=lowhigh_palette, ax=ax)
    ax.set_xlabel('Question Type')
    ax.set_xticklabels(['Observed', 'Same Domain', 'Diff Domain'])
    ax.set_title(exp.replace('-', ' ').title(), fontweight='bold')
    ax.set_ylim([0, 1])
    if i == 0:
        ax.set_ylabel('Expected Commonality', fontweight='bold')
        ax.get_legend().remove()
    else:
        ax.legend(title='Stance', labels=['Opposing', 'Shared'], frameon=False)
plt.tight_layout()
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure2a_gradient.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

```{r}
main_df <- read.csv('/tmp/main_df.csv')

model <- glmer(predictShared ~ experiment_num * stance_num * category_num +
               (1|pid) + (1|matchedDomain),
               data = main_df, family = binomial)
summary(model)
confint(model, method = "Wald")
```

## 4. SR-G Prediction (Figure 2B)

Paper reports: commonality → SR-G β = 1.84, CI [1.60, 2.08]; three-way interaction β = −0.47, CI [−0.71, −0.23] (p.8)

```{python}
# Aggregate by participant (excluding observed question)
inf_df = df_pd[df_pd['question'] != df_pd['matchedIdx']]
srg_df = inf_df.groupby(['experiment', 'stance', 'pid', 'matchedDomain']).agg({
    'predictShared': 'mean', 'srgiResponse': 'mean',
    'experiment_num': 'first', 'stance_num': 'first'
}).reset_index()
```

```{python}
#| fig-cap: "Figure 2B: SR-G ~ Commonality"
#| fig-width: 9
#| fig-height: 4
g = sns.lmplot(data=srg_df, x='predictShared', y='srgiResponse',
               hue='stance', hue_order=['opposing', 'shared'],
               col='experiment', col_order=['no-chat', 'chat'],
               palette=lowhigh_palette, scatter_kws={'alpha': 0.3}, legend=False)
g.set_xlabels('Expected Commonality', fontweight='bold');
g.set_ylabels('SR-G', fontweight='bold');
g.set_titles('{col_name}');
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure2b_srg.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

```{python}
#| output: false
srg_df.to_csv('/tmp/srg_df.csv', index=False)
```

```{r}
srg_df <- read.csv('/tmp/srg_df.csv')
model <- lmer(srgiResponse ~ predictShared * experiment_num * stance_num + (1|matchedDomain),
              data = srg_df)
summary(model)
confint(model, method = "Wald")
```

## 5. Distance-Commonality (Figure 5 SI)

Paper reports: distance β = −1.32, CI [−1.36, −1.29]; distance × experiment β = −0.32, CI [−0.36, −0.29] (p.6)

```{python}
#| fig-cap: "Figure 5 (SI): Distance-commonality"
#| fig-width: 10
#| fig-height: 4
inf_grouped = inf_df.groupby(['experiment', 'stance', 'pid', 'distance'])['predictShared'].mean().reset_index()
g = sns.FacetGrid(data=inf_grouped, col='experiment', col_order=['no-chat', 'chat'], height=4)
g.map_dataframe(sns.barplot, x='distance', y='predictShared', hue='stance', palette=lowhigh_palette);
g.set_axis_labels('|Prediction - Own Response|', 'Expected Commonality', fontweight='bold');
g.set_titles('{col_name}');
plt.ylim([0, 1])
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure5_distance.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

```{python}
#| output: false
inf_df.to_csv('/tmp/inf_df.csv', index=False)
```

```{r}
inf_df <- read.csv('/tmp/inf_df.csv')
model <- glmer(predictShared ~ distance_num * experiment_num * stance_num + (1|pid),
               data = inf_df, family = binomial)
summary(model)
confint(model, method = "Wald")
```

## 6. Domain Analysis (Figure 3 + Domain-Specific Models)

Paper reports: 42 models (7 domains × 3 types × 2 stances), >95% positive coefficients, all significant effects positive after FDR (p.9)

```{python}
#| fig-cap: "Figure 3: Domain-level heatmaps"
#| fig-width: 10
#| fig-height: 10
domain_order = ['Lifestyle', 'Background', 'Identity', 'Morality', 'Politics', 'Preferences', 'Religion']
category_order = ['sameQ', 'sameD', 'diffD']
category_labels = ['Same\nQuestion', 'Same\nDomain', 'Different\nDomain']

df_pd['domain_cap'] = df_pd['matchedDomain'].str.replace('arbitrary', 'Lifestyle').str.capitalize()
heatmap_data = df_pd.groupby(['experiment', 'stance', 'domain_cap', 'category'])['predictShared'].mean().reset_index()

fig, axes = plt.subplots(3, 2, figsize=(10, 10), sharex=True)

for row, exp in enumerate(['chat', 'no-chat']):
    for col_idx, stance in enumerate(['opposing', 'shared']):
        ax = axes[row, col_idx]
        subset = heatmap_data[(heatmap_data['experiment'] == exp) & (heatmap_data['stance'] == stance)]
        pivot = subset.pivot(index='domain_cap', columns='category', values='predictShared')
        pivot = pivot.reindex(index=domain_order, columns=category_order)
        sns.heatmap(pivot, ax=ax, cmap='YlOrRd', vmin=0, vmax=1, cbar=(col_idx == 1),
                    cbar_kws={'label': '% Commonality'} if col_idx == 1 else {})
        ax.set_xticklabels(category_labels, rotation=45, ha='right')
        ax.set_ylabel('Domain' if col_idx == 0 else '')
        ax.set_xlabel('')
        if row == 0:
            ax.set_title(stance.capitalize(), fontweight='bold')

# Contrast row
for col_idx, stance in enumerate(['opposing', 'shared']):
    ax = axes[2, col_idx]
    chat = heatmap_data[(heatmap_data['experiment'] == 'chat') & (heatmap_data['stance'] == stance)]
    nochat = heatmap_data[(heatmap_data['experiment'] == 'no-chat') & (heatmap_data['stance'] == stance)]
    merged = chat.merge(nochat, on=['domain_cap', 'category'], suffixes=('_chat', '_nochat'))
    merged['diff'] = merged['predictShared_chat'] - merged['predictShared_nochat']
    pivot = merged.pivot(index='domain_cap', columns='category', values='diff')
    pivot = pivot.reindex(index=domain_order, columns=category_order)
    sns.heatmap(pivot, ax=ax, cmap='RdBu_r', center=0, vmin=-0.3, vmax=0.3, cbar=(col_idx == 1),
                cbar_kws={'label': 'Chat - No-Chat'} if col_idx == 1 else {})
    ax.set_xticklabels(category_labels, rotation=45, ha='right')
    ax.set_ylabel('Domain' if col_idx == 0 else '')

axes[0, 0].text(-0.3, 0.5, 'Chat', transform=axes[0, 0].transAxes, fontweight='bold', va='center', rotation=90)
axes[1, 0].text(-0.3, 0.5, 'No-Chat', transform=axes[1, 0].transAxes, fontweight='bold', va='center', rotation=90)
axes[2, 0].text(-0.3, 0.5, 'Contrast', transform=axes[2, 0].transAxes, fontweight='bold', va='center', rotation=90)

plt.tight_layout()
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure3_heatmaps.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

### 42 Domain-Specific Models

```{r}
domain_df <- read.csv('/tmp/main_df.csv')
domain_df$experiment <- factor(domain_df$experiment, levels = c('no-chat', 'chat'))
contrasts(domain_df$experiment) <- cbind(c(-0.5, 0.5))

fit_model <- function(data, cat) {
    if (cat == 'sameQ') {
        m <- glm(predictShared ~ experiment, data = data, family = binomial())
    } else {
        m <- glmer(predictShared ~ experiment + (1|pid), data = data, family = binomial(),
                   control = glmerControl(optimizer = 'bobyqa', optCtrl = list(maxfun = 100000)))
    }
    tibble(beta = coef(summary(m))[2, 1], pVal = coef(summary(m))[2, 4])
}

results <- domain_df %>%
    group_by(matchedDomain, category, stance) %>%
    nest() %>%
    mutate(res = map2(data, category, fit_model)) %>%
    select(-data) %>%
    unnest(res) %>%
    ungroup() %>%
    mutate(pVal_fdr = p.adjust(pVal, method = 'fdr'))

n_pos <- sum(results$beta > 0)
n_sig_pos <- sum(results$pVal_fdr < 0.05 & results$beta > 0)
n_sig_neg <- sum(results$pVal_fdr < 0.05 & results$beta < 0)

cat(sprintf('Total models: %d\n', nrow(results)))
cat(sprintf('Positive coefficients: %d (%.1f%%)\n', n_pos, 100 * n_pos / nrow(results)))
cat(sprintf('Significant after FDR: %d positive, %d negative\n', n_sig_pos, n_sig_neg))
cat('\nPaper reports: >95% positive, all significant effects positive\n')
```

## 7. Prior Calibration (SI)

Paper reports: β = 0.15, CI [0.09, 0.21] for population rate predicting commonality.

```{python}
# Use main behavioral data for prior calibration
emp = pd.read_csv(data_dir / 'experiment_data.csv')
n_participants = emp['pid'].nunique()

props = emp.groupby(['question', 'preChatResponse']).size().reset_index(name='count')
props['prop'] = props['count'] / n_participants

joint = []
for _, row in props.iterrows():
    subset = emp[(emp['question'] == row['question']) & (emp['preChatResponse'] == row['preChatResponse'])]
    joint.append(subset['predictShared'].mean() if len(subset) > 0 else np.nan)
props['joint'] = joint
props = props.dropna()

slope, intercept, r, p, se = linregress(props['prop'], props['joint'])
print(f'β = {slope:.2f}, 95% CI: [{slope - 1.96*se:.2f}, {slope + 1.96*se:.2f}], r = {r:.2f}')
print(f'Paper reports: β = 0.15, CI [0.09, 0.21]')
```

```{python}
#| fig-width: 5
#| fig-height: 4
fig, ax = plt.subplots(figsize=(5, 4))
sns.regplot(x='prop', y='joint', data=props, ax=ax,
            scatter_kws={'alpha': 0.5}, line_kws={'color': '#3a0ca3'})
ax.set_xlabel('Population Response Proportion', fontweight='bold')
ax.set_ylabel('P(Expect Shared)', fontweight='bold')
ax.set_xlim([0, 1])
ax.set_ylim([0, 1])
ax.text(0.05, 0.95, f'r = {r:.2f}', transform=ax.transAxes)
plt.title('Prior Calibration')
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'prior_calibration.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

## 8. Sample Description

```{python}
print('=== Sample Description ===')
print(f"Total participants: N = {df_pd['pid'].nunique()}")
print(f"  No-chat: n = {df_pd[df_pd['experiment'] == 'no-chat']['pid'].nunique()}")
print(f"  Chat: n = {df_pd[df_pd['experiment'] == 'chat']['pid'].nunique()}")
print(f"  Chat dyads: {df_pd[df_pd['experiment'] == 'chat']['dyadId'].nunique()}")
print(f'\nPaper reports: N = 1,205 (527 imagined; 678 real, 339 dyads)')
```
