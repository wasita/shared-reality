---
title: "Commonality Inference: Paper Analyses"
author: "Reproducibility Code"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
engine: knitr
execute:
  warning: false
  message: false
  cache: true
knitr:
  opts_chunk:
    message: false
    warning: false
    cache: true
---

This document reproduces all behavioral analyses and figures from the paper.

1. **Setup** - Imports and data loading
2. **Manipulation Check** - Stance recognition (Paper p.6)
3. **Generalization Gradient** - Figure 2A + main model (Paper p.8-9)
4. **SR-G Prediction** - Figure 2B + model (Paper p.8)
5. **Distance-Commonality** - Figure 5 SI + model (Paper p.6)
6. **Domain Analysis** - Figure 3 + 42 domain-specific models (Paper p.9)
7. **Prior Calibration** - SI analysis
8. **Sample Description** - Methods section

## 1. Setup

```{r}
#| label: setup
#| include: false
library(reticulate)
use_python(Sys.which("python3"), required = TRUE)
library(lme4)
library(lmerTest)
library(dplyr)
library(tidyr)
library(purrr)
```

```{python}
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr, linregress
from scipy import stats
from statsmodels.stats.multitest import multipletests
import polars as pl
from polars import col, lit

plt.rcParams['font.family'] = 'Helvetica Neue'
sns.set_style('whitegrid')
SAVE_FIGURES = False
```

```{python}
# Find project root
base_dir = Path.cwd().resolve()
while base_dir.name and not (base_dir / 'data').exists():
    base_dir = base_dir.parent
if not (base_dir / 'data').exists():
    raise ValueError('Could not find project root with data directory')

data_dir = base_dir / 'data'
figures_dir = base_dir / 'outputs' / 'figures'
figures_dir.mkdir(parents=True, exist_ok=True)

lowhigh_palette = ['#648FFF', '#DC267F']  # low (blue), high (pink)
print(f'Data directory: {data_dir}')
```

### Load and preprocess data

```{python}
# Load pre-merged behavioral data
df = pl.read_csv(data_dir / 'responses.csv')
df = df.filter(~col('matchedTolerance').is_null())

# Derived variables
df = df.with_columns([
    pl.when(col('matchedTolerance') <= 1).then(lit('shared')).otherwise(lit('opposing')).alias('stance'),
    pl.when(col('matchedQuestion') == col('preChatQuestion')).then(lit('sameQ'))
     .when(col('matchedDomain') == col('preChatDomain')).then(lit('sameD'))
     .otherwise(lit('diffD')).alias('category'),
    (col('postChatResponse') - col('preChatResponse')).abs().alias('distance')
]).rename({'groupId': 'dyadId'})

# Convert to pandas with numeric contrasts
df_pd = df.to_pandas()
df_pd['stance_num'] = df_pd['stance'].map({'opposing': -1, 'shared': 1})
df_pd['category_num'] = df_pd['category'].map({'sameQ': 1, 'sameD': 0, 'diffD': -1}).astype(float)
df_pd['experiment_num'] = df_pd['experiment'].map({'no-chat': -1, 'chat': 1})
df_pd['distance_num'] = df_pd['distance'].map({0: 2, 1: 1, 2: 0, 3: -1, 4: -2})

print(f'Loaded {len(df_pd)} observations from {df_pd["pid"].nunique()} participants')
```

```{python}
#| output: false
# Save main data for R (once)
df_pd.to_csv('/tmp/main_df.csv', index=False)
```

## 2. Manipulation Check

Participants should accurately perceive agreement/disagreement on the focal topic. Paper reports the 2×2 breakdown: "judging it as shared far more often when they actually agreed (79% observation-only, 89% chat) than when they disagreed (19% observation-only, 38% chat)."

```{python}
# Filter to observed/focal question only
obs_df = df_pd[df_pd['question'] == df_pd['matchedIdx']]

print('=== Manipulation Check: P(judged shared) on FOCAL question ===\n')

# 2x2 table
print('                        Actual Stance')
print('                   Shared          Opposing')
print('Interaction    (high-match)     (low-match)')
print('-' * 50)

manip_results = []
for exp in ['no-chat', 'chat']:
    for stance in ['shared', 'opposing']:
        cell = obs_df[(obs_df['experiment'] == exp) & (obs_df['stance'] == stance)]
        n = len(cell)
        p_shared = cell['predictShared'].mean()
        manip_results.append({
            'experiment': exp,
            'stance': stance,
            'n': n,
            'p_shared': p_shared
        })

manip_df = pd.DataFrame(manip_results)

for exp in ['no-chat', 'chat']:
    exp_data = manip_df[manip_df['experiment'] == exp]
    shared = exp_data[exp_data['stance'] == 'shared'].iloc[0]
    opposing = exp_data[exp_data['stance'] == 'opposing'].iloc[0]
    label = "No-Chat" if exp == 'no-chat' else "Chat"
    print(f"{label:12}   {shared['p_shared']*100:5.1f}% (n={int(shared['n'])})   {opposing['p_shared']*100:5.1f}% (n={int(opposing['n'])})")

print('-' * 50)

# Discrimination by condition
print('\n=== Discrimination (Shared - Opposing) ===\n')
for exp in ['no-chat', 'chat']:
    exp_data = manip_df[manip_df['experiment'] == exp]
    p_shared = exp_data[exp_data['stance'] == 'shared']['p_shared'].values[0]
    p_opposing = exp_data[exp_data['stance'] == 'opposing']['p_shared'].values[0]
    discrim = p_shared - p_opposing
    label = "No-Chat" if exp == 'no-chat' else "Chat"
    print(f"{label:12}: {discrim*100:+.1f} percentage points")

print('\n→ Both conditions show strong discrimination')
print('→ Chat elevates commonality judgments in BOTH cells')
print('  (even when partners disagreed, conversation led to perceiving more common ground)')
```

```{python}
#| fig-width: 8
#| fig-height: 4
fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)

for i, exp in enumerate(['no-chat', 'chat']):
    ax = axes[i]
    exp_data = obs_df[obs_df['experiment'] == exp]
    sns.barplot(data=exp_data, x='stance', y='predictShared', order=['opposing', 'shared'],
                hue='stance', palette=lowhigh_palette, ax=ax, legend=False)
    ax.set_xlabel('Stance Condition')
    ax.set_ylabel('P(judged shared)' if i == 0 else '')
    ax.set_ylim([0, 1])
    ax.set_title(exp.replace('-', ' ').title(), fontweight='bold')

    # Add N labels
    for j, stance in enumerate(['opposing', 'shared']):
        n = len(exp_data[exp_data['stance'] == stance])
        ax.text(j, 0.05, f'n={n}', ha='center', fontsize=9, color='white')

sns.despine()
plt.suptitle('Manipulation Check: Focal Question', fontweight='bold', y=1.02)
plt.tight_layout()
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'manipulation_check.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

## 3. Generalization Gradient (Figure 2A)

Paper reports: stance × question type interaction β = 0.54, 95% CI [0.48, 0.59] (p.8-9)

```{python}
#| fig-cap: "Figure 2A: Generalization gradient"
#| fig-width: 10
#| fig-height: 4
fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)
for i, exp in enumerate(['no-chat', 'chat']):
    ax = axes[i]
    sns.barplot(data=df_pd[df_pd['experiment'] == exp], x='category', y='predictShared',
                order=['sameQ', 'sameD', 'diffD'], hue='stance', hue_order=['opposing', 'shared'],
                palette=lowhigh_palette, ax=ax)
    ax.set_xlabel('Question Type')
    ax.set_xticklabels(['Observed', 'Same Domain', 'Diff Domain'])
    ax.set_title(exp.replace('-', ' ').title(), fontweight='bold')
    ax.set_ylim([0, 1])
    if i == 0:
        ax.set_ylabel('Expected Commonality', fontweight='bold')
        ax.get_legend().remove()
    else:
        ax.legend(title='Stance', labels=['Opposing', 'Shared'], frameon=False)
plt.tight_layout()
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure2a_gradient.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

```{r}
main_df <- read.csv('/tmp/main_df.csv')

model <- glmer(predictShared ~ experiment_num * stance_num * category_num +
               (1|pid) + (1|matchedDomain),
               data = main_df, family = binomial)
summary(model)
confint(model, method = "Wald")
```

## 4. SR-G Prediction (Figure 2B)

Paper reports: commonality → SR-G β = 1.84, CI [1.60, 2.08]; three-way interaction β = −0.47, CI [−0.71, −0.23] (p.8)

```{python}
# Aggregate by participant (excluding observed question)
inf_df = df_pd[df_pd['question'] != df_pd['matchedIdx']]
srg_df = inf_df.groupby(['experiment', 'stance', 'pid', 'matchedDomain']).agg({
    'predictShared': 'mean', 'srgiResponse': 'mean',
    'experiment_num': 'first', 'stance_num': 'first'
}).reset_index()
```

```{python}
#| fig-cap: "Figure 2B: SR-G ~ Commonality"
#| fig-width: 9
#| fig-height: 4
g = sns.lmplot(data=srg_df, x='predictShared', y='srgiResponse',
               hue='stance', hue_order=['opposing', 'shared'],
               col='experiment', col_order=['no-chat', 'chat'],
               palette=lowhigh_palette, scatter_kws={'alpha': 0.3}, legend=False)
g.set_xlabels('Expected Commonality', fontweight='bold');
g.set_ylabels('SR-G', fontweight='bold');
g.set_titles('{col_name}');
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure2b_srg.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

```{python}
#| output: false
srg_df.to_csv('/tmp/srg_df.csv', index=False)
```

```{r}
srg_df <- read.csv('/tmp/srg_df.csv')
model <- lmer(srgiResponse ~ predictShared * experiment_num * stance_num + (1|matchedDomain),
              data = srg_df)
summary(model)
confint(model, method = "Wald")
```

## 5. Distance-Commonality (Figure S1)

Paper reports: distance β = −1.32, CI [−1.36, −1.29]; distance × experiment β = −0.32, CI [−0.36, −0.29] (p.6)

Commonality expectations as a function of predicted distance between partner and self. Fill color indicates stance (pink is shared, blue is opposing) and panel position indicates interaction type (left is imagined, right is real).

```{python}
#| fig-cap: "Figure S1: Commonality expectations as a function of predicted distance"
#| fig-width: 10
#| fig-height: 5

# Aggregate by participant first
inf_grouped = inf_df.groupby(['experiment', 'stance', 'pid', 'distance'])['predictShared'].mean().reset_index()

# Bootstrap CI function
def bootstrap_ci(data, n_boot=1000, ci=95):
    boot_means = [np.random.choice(data, size=len(data), replace=True).mean() for _ in range(n_boot)]
    lower = np.percentile(boot_means, (100 - ci) / 2)
    upper = np.percentile(boot_means, 100 - (100 - ci) / 2)
    return lower, upper

# Compute means and CIs
summary_data = []
for exp in ['no-chat', 'chat']:
    for stance in ['opposing', 'shared']:
        for dist in range(5):
            subset = inf_grouped[(inf_grouped['experiment'] == exp) &
                                  (inf_grouped['stance'] == stance) &
                                  (inf_grouped['distance'] == dist)]['predictShared']
            if len(subset) > 0:
                mean_val = subset.mean()
                ci_low, ci_high = bootstrap_ci(subset.values)
                summary_data.append({
                    'experiment': exp, 'stance': stance, 'distance': dist,
                    'mean': mean_val, 'ci_low': ci_low, 'ci_high': ci_high
                })

summary_df = pd.DataFrame(summary_data)

# Create figure
fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)
plt.rcParams.update({'font.size': 12})

exp_labels = {'no-chat': 'Imagined', 'chat': 'Real'}
stance_colors = {'opposing': '#648FFF', 'shared': '#DC267F'}  # blue, pink

for i, exp in enumerate(['no-chat', 'chat']):
    ax = axes[i]
    exp_data = summary_df[summary_df['experiment'] == exp]

    bar_width = 0.35
    x = np.arange(5)

    for j, stance in enumerate(['opposing', 'shared']):
        stance_data = exp_data[exp_data['stance'] == stance].sort_values('distance')
        offset = -bar_width/2 if stance == 'opposing' else bar_width/2

        bars = ax.bar(x + offset, stance_data['mean'], bar_width,
                      color=stance_colors[stance], alpha=0.8,
                      label=stance.capitalize() if i == 1 else '')

        # Error bars - no caps
        ax.errorbar(x + offset, stance_data['mean'],
                    yerr=[stance_data['mean'] - stance_data['ci_low'],
                          stance_data['ci_high'] - stance_data['mean']],
                    fmt='none', color='black', capsize=0, linewidth=1.5)

    ax.set_xlabel('Predicted Distance\n(|Prediction for Partner − Own|)', fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(['0', '1', '2', '3', '4'], fontsize=12)
    ax.set_ylim([0, 1])
    ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])
    ax.text(-0.1, 1.05, chr(65 + i), transform=ax.transAxes, fontsize=16, fontweight='bold', va='bottom')
    ax.set_title(exp_labels[exp], fontsize=14, fontweight='bold')
    ax.tick_params(labelsize=11)
    ax.grid(False)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    if i == 0:
        ax.set_ylabel('Commonality Expectation', fontsize=14)
    if i == 1:
        ax.legend(title='Stance', frameon=False, loc='upper right', fontsize=11)

plt.tight_layout()
plt.savefig(figures_dir / 'figure_s1.pdf', dpi=300, bbox_inches='tight')
plt.savefig(figures_dir / 'figure_s1.png', dpi=150, bbox_inches='tight')
plt.show()

print(f'\nFigure S1 saved to {figures_dir / "figure_s1.pdf"}')
```

```{python}
#| output: false
inf_df.to_csv('/tmp/inf_df.csv', index=False)
```

```{r}
inf_df <- read.csv('/tmp/inf_df.csv')
model <- glmer(predictShared ~ distance_num * experiment_num * stance_num + (1|pid),
               data = inf_df, family = binomial)
summary(model)
confint(model, method = "Wald")
```

## 6. Domain Analysis (Figure 3 + Domain-Specific Models)

Paper reports: 42 models (7 domains × 3 types × 2 stances), >95% positive coefficients, all significant effects positive after FDR (p.9)

```{python}
#| fig-cap: "Figure 3: Domain-level heatmaps"
#| fig-width: 10
#| fig-height: 10
domain_order = ['Lifestyle', 'Background', 'Identity', 'Morality', 'Politics', 'Preferences', 'Religion']
category_order = ['sameQ', 'sameD', 'diffD']
category_labels = ['Same\nQuestion', 'Same\nDomain', 'Different\nDomain']

df_pd['domain_cap'] = df_pd['matchedDomain'].str.replace('arbitrary', 'Lifestyle').str.capitalize()
heatmap_data = df_pd.groupby(['experiment', 'stance', 'domain_cap', 'category'])['predictShared'].mean().reset_index()

fig, axes = plt.subplots(3, 2, figsize=(10, 10), sharex=True)

for row, exp in enumerate(['chat', 'no-chat']):
    for col_idx, stance in enumerate(['opposing', 'shared']):
        ax = axes[row, col_idx]
        subset = heatmap_data[(heatmap_data['experiment'] == exp) & (heatmap_data['stance'] == stance)]
        pivot = subset.pivot(index='domain_cap', columns='category', values='predictShared')
        pivot = pivot.reindex(index=domain_order, columns=category_order)
        sns.heatmap(pivot, ax=ax, cmap='YlOrRd', vmin=0, vmax=1, cbar=(col_idx == 1),
                    cbar_kws={'label': '% Commonality'} if col_idx == 1 else {})
        ax.set_xticklabels(category_labels, rotation=45, ha='right')
        ax.set_ylabel('Domain' if col_idx == 0 else '')
        ax.set_xlabel('')
        if row == 0:
            ax.set_title(stance.capitalize(), fontweight='bold')

# Contrast row
for col_idx, stance in enumerate(['opposing', 'shared']):
    ax = axes[2, col_idx]
    chat = heatmap_data[(heatmap_data['experiment'] == 'chat') & (heatmap_data['stance'] == stance)]
    nochat = heatmap_data[(heatmap_data['experiment'] == 'no-chat') & (heatmap_data['stance'] == stance)]
    merged = chat.merge(nochat, on=['domain_cap', 'category'], suffixes=('_chat', '_nochat'))
    merged['diff'] = merged['predictShared_chat'] - merged['predictShared_nochat']
    pivot = merged.pivot(index='domain_cap', columns='category', values='diff')
    pivot = pivot.reindex(index=domain_order, columns=category_order)
    sns.heatmap(pivot, ax=ax, cmap='RdBu_r', center=0, vmin=-0.3, vmax=0.3, cbar=(col_idx == 1),
                cbar_kws={'label': 'Chat - No-Chat'} if col_idx == 1 else {})
    ax.set_xticklabels(category_labels, rotation=45, ha='right')
    ax.set_ylabel('Domain' if col_idx == 0 else '')

axes[0, 0].text(-0.3, 0.5, 'Chat', transform=axes[0, 0].transAxes, fontweight='bold', va='center', rotation=90)
axes[1, 0].text(-0.3, 0.5, 'No-Chat', transform=axes[1, 0].transAxes, fontweight='bold', va='center', rotation=90)
axes[2, 0].text(-0.3, 0.5, 'Contrast', transform=axes[2, 0].transAxes, fontweight='bold', va='center', rotation=90)

plt.tight_layout()
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure3_heatmaps.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

### 42 Domain-Specific Models

```{r}
domain_df <- read.csv('/tmp/main_df.csv')
domain_df$experiment <- factor(domain_df$experiment, levels = c('no-chat', 'chat'))
contrasts(domain_df$experiment) <- cbind(c(-0.5, 0.5))

fit_model <- function(data, cat) {
    if (cat == 'sameQ') {
        m <- glm(predictShared ~ experiment, data = data, family = binomial())
    } else {
        m <- glmer(predictShared ~ experiment + (1|pid), data = data, family = binomial(),
                   control = glmerControl(optimizer = 'bobyqa', optCtrl = list(maxfun = 100000)))
    }
    tibble(beta = coef(summary(m))[2, 1], pVal = coef(summary(m))[2, 4])
}

results <- domain_df %>%
    group_by(matchedDomain, category, stance) %>%
    nest() %>%
    mutate(res = map2(data, category, fit_model)) %>%
    select(-data) %>%
    unnest(res) %>%
    ungroup() %>%
    mutate(pVal_fdr = p.adjust(pVal, method = 'fdr'))

n_pos <- sum(results$beta > 0)
n_sig_pos <- sum(results$pVal_fdr < 0.05 & results$beta > 0)
n_sig_neg <- sum(results$pVal_fdr < 0.05 & results$beta < 0)

cat(sprintf('Total models: %d\n', nrow(results)))
cat(sprintf('Positive coefficients: %d (%.1f%%)\n', n_pos, 100 * n_pos / nrow(results)))
cat(sprintf('Significant after FDR: %d positive, %d negative\n', n_sig_pos, n_sig_neg))
cat('\nPaper reports: >95% positive, all significant effects positive\n')
```

## 7. Prior Calibration (SI)

Paper reports: β = 0.15, CI [0.09, 0.21] for population rate predicting commonality.

```{python}
# Use main behavioral data for prior calibration
emp = pd.read_csv(data_dir / 'responses.csv')
n_participants = emp['pid'].nunique()

props = emp.groupby(['question', 'preChatResponse']).size().reset_index(name='count')
props['prop'] = props['count'] / n_participants

joint = []
for _, row in props.iterrows():
    subset = emp[(emp['question'] == row['question']) & (emp['preChatResponse'] == row['preChatResponse'])]
    joint.append(subset['predictShared'].mean() if len(subset) > 0 else np.nan)
props['joint'] = joint
props = props.dropna()

slope, intercept, r, p, se = linregress(props['prop'], props['joint'])
print(f'β = {slope:.2f}, 95% CI: [{slope - 1.96*se:.2f}, {slope + 1.96*se:.2f}], r = {r:.2f}')
print(f'Paper reports: β = 0.15, CI [0.09, 0.21]')
```

```{python}
#| fig-width: 5
#| fig-height: 4
fig, ax = plt.subplots(figsize=(5, 4))
sns.regplot(x='prop', y='joint', data=props, ax=ax,
            scatter_kws={'alpha': 0.5}, line_kws={'color': '#3a0ca3'})
ax.set_xlabel('Population Response Proportion', fontweight='bold')
ax.set_ylabel('P(Expect Shared)', fontweight='bold')
ax.set_xlim([0, 1])
ax.set_ylim([0, 1])
ax.text(0.05, 0.95, f'r = {r:.2f}', transform=ax.transAxes)
plt.title('Prior Calibration')
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'prior_calibration.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

## 8. Sample Description

```{python}
print('=== Sample Description ===')
print(f"Total participants: N = {df_pd['pid'].nunique()}")
print(f"  No-chat: n = {df_pd[df_pd['experiment'] == 'no-chat']['pid'].nunique()}")
print(f"  Chat: n = {df_pd[df_pd['experiment'] == 'chat']['pid'].nunique()}")
print(f"  Chat dyads: {df_pd[df_pd['experiment'] == 'chat']['dyadId'].nunique()}")
print(f'\nPaper reports: N = 1,205 (527 imagined; 678 real, 339 dyads)')
```
