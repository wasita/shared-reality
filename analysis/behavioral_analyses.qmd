---
title: "Commonality Inference: Paper Analyses"
author: "Reproducibility Code"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
engine: knitr
execute:
  warning: false
  message: false
  cache: true
knitr:
  opts_chunk:
    message: false
    warning: false
    cache: true
---

This document reproduces all behavioral analyses and figures from the paper.

1. **Setup** - Imports and data loading
2. **Manipulation Check** - Stance recognition (Paper p.6)
3. **Generalization Gradient** - Figure 2A + main model (Paper p.8-9)
4. **SR-G Prediction** - Figure 2B + model (Paper p.8)
5. **Distance-Commonality** - Figure 5 SI + model (Paper p.6)
6. **Domain Analysis** - Figure 3 + 42 domain-specific models (Paper p.9)
7. **Prior Calibration** - SI analysis
8. **Sample Description** - Methods section

## 1. Setup

```{r}
#| label: setup
#| include: false
library(reticulate)
use_python(Sys.which("python3"), required = TRUE)
library(lme4)
library(lmerTest)
library(dplyr)
library(tidyr)
library(purrr)
```

```{python}
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr, linregress
from scipy import stats
from statsmodels.stats.multitest import multipletests
import polars as pl
from polars import col, lit

plt.rcParams['font.family'] = 'Helvetica Neue'
sns.set_style('whitegrid')
SAVE_FIGURES = True
```

```{python}
# Find project root
base_dir = Path.cwd().resolve()
while base_dir.name and not (base_dir / 'data').exists():
    base_dir = base_dir.parent
if not (base_dir / 'data').exists():
    raise ValueError('Could not find project root with data directory')

data_dir = base_dir / 'data'
figures_dir = base_dir / 'outputs' / 'figures'
figures_dir.mkdir(parents=True, exist_ok=True)

lowhigh_palette = ['#648FFF', '#DC267F']  # low (blue), high (pink)
print(f'Data directory: {data_dir}')
```

### Load and preprocess data

```{python}
# Load pre-merged behavioral data
df = pl.read_csv(data_dir / 'responses.csv')
df = df.filter(~col('matchedTolerance').is_null())

# Derived variables
df = df.with_columns([
    pl.when(col('matchedTolerance') <= 1).then(lit('shared')).otherwise(lit('opposing')).alias('stance'),
    pl.when(col('matchedQuestion') == col('preChatQuestion')).then(lit('sameQ'))
     .when(col('matchedDomain') == col('preChatDomain')).then(lit('sameD'))
     .otherwise(lit('diffD')).alias('category'),
    (col('postChatResponse') - col('preChatResponse')).abs().alias('distance')
]).rename({'groupId': 'dyadId'})

# Convert to pandas with numeric contrasts
df_pd = df.to_pandas()
df_pd['stance_num'] = df_pd['stance'].map({'opposing': -1, 'shared': 1})
df_pd['category_num'] = df_pd['category'].map({'sameQ': 1, 'sameD': 0, 'diffD': -1}).astype(float)
df_pd['experiment_num'] = df_pd['experiment'].map({'no-chat': -1, 'chat': 1})
df_pd['distance_num'] = df_pd['distance'].map({0: 2, 1: 1, 2: 0, 3: -1, 4: -2})

print(f'Loaded {len(df_pd)} observations from {df_pd["pid"].nunique()} participants')
```

```{python}
#| output: false
# Save main data for R (once)
df_pd.to_csv('/tmp/main_df.csv', index=False)
```

## 2. Manipulation Check

Participants should accurately perceive agreement/disagreement on the focal topic. Paper reports the 2×2 breakdown: "judging it as shared far more often when they actually agreed (79% observation-only, 89% chat) than when they disagreed (19% observation-only, 38% chat)."

```{python}
# Filter to observed/focal question only
obs_df = df_pd[df_pd['question'] == df_pd['matchedIdx']]

print('=== Manipulation Check: P(judged shared) on FOCAL question ===\n')

# 2x2 table
print('                        Actual Stance')
print('                   Shared          Opposing')
print('Interaction    (high-match)     (low-match)')
print('-' * 50)

manip_results = []
for exp in ['no-chat', 'chat']:
    for stance in ['shared', 'opposing']:
        cell = obs_df[(obs_df['experiment'] == exp) & (obs_df['stance'] == stance)]
        n = len(cell)
        p_shared = cell['predictShared'].mean()
        manip_results.append({
            'experiment': exp,
            'stance': stance,
            'n': n,
            'p_shared': p_shared
        })

manip_df = pd.DataFrame(manip_results)

for exp in ['no-chat', 'chat']:
    exp_data = manip_df[manip_df['experiment'] == exp]
    shared = exp_data[exp_data['stance'] == 'shared'].iloc[0]
    opposing = exp_data[exp_data['stance'] == 'opposing'].iloc[0]
    label = "No-Chat" if exp == 'no-chat' else "Chat"
    print(f"{label:12}   {shared['p_shared']*100:5.1f}% (n={int(shared['n'])})   {opposing['p_shared']*100:5.1f}% (n={int(opposing['n'])})")

print('-' * 50)

# Discrimination by condition
print('\n=== Discrimination (Shared - Opposing) ===\n')
for exp in ['no-chat', 'chat']:
    exp_data = manip_df[manip_df['experiment'] == exp]
    p_shared = exp_data[exp_data['stance'] == 'shared']['p_shared'].values[0]
    p_opposing = exp_data[exp_data['stance'] == 'opposing']['p_shared'].values[0]
    discrim = p_shared - p_opposing
    label = "No-Chat" if exp == 'no-chat' else "Chat"
    print(f"{label:12}: {discrim*100:+.1f} percentage points")

print('\n→ Both conditions show strong discrimination')
print('→ Chat elevates commonality judgments in BOTH cells')
print('  (even when partners disagreed, conversation led to perceiving more common ground)')
```

## 3. Generalization Gradient (Figure 2A)

Paper reports: stance × question type interaction β = 0.54, 95% CI [0.48, 0.59] (p.8-9)

```{python}
#| fig-cap: "Figure 2A: Generalization gradient"
#| fig-width: 10
#| fig-height: 4
fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)
for i, exp in enumerate(['no-chat', 'chat']):
    ax = axes[i]
    sns.barplot(data=df_pd[df_pd['experiment'] == exp], x='category', y='predictShared',
                order=['sameQ', 'sameD', 'diffD'], hue='stance', hue_order=['opposing', 'shared'],
                palette=lowhigh_palette, ax=ax)
    ax.set_xlabel('Question Type')
    ax.set_xticklabels(['Observed', 'Same Domain', 'Diff Domain'])
    ax.set_title(exp.replace('-', ' ').title(), fontweight='bold')
    ax.set_ylim([0, 1])
    if i == 0:
        ax.set_ylabel('Expected Commonality', fontweight='bold')
        ax.get_legend().remove()
    else:
        ax.legend(title='Stance', labels=['Opposing', 'Shared'], frameon=False)
plt.tight_layout()
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure2a_gradient.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

```{r}
main_df <- read.csv('/tmp/main_df.csv')

model <- glmer(predictShared ~ experiment_num * stance_num * category_num +
               (1|pid) + (1|matchedDomain),
               data = main_df, family = binomial)
summary(model)
confint(model, method = "Wald")
```

## 4. SR-G Prediction (Figure 2B)

Paper reports: commonality → SR-G β = 1.84, CI [1.60, 2.08]; three-way interaction β = −0.47, CI [−0.71, −0.23] (p.8)

```{python}
# Aggregate by participant (excluding observed question)
# Reload df_pd if needed (Python state can be lost between chunks)
if 'df_pd' not in dir():
    import pandas as pd
    df_pd = pd.read_csv('/tmp/main_df.csv', low_memory=False)

inf_df = df_pd[df_pd['question'] != df_pd['matchedIdx']]
inf_df.to_csv('/tmp/inf_df.csv', index=False)  # Save for later chunks

srg_df = inf_df.groupby(['experiment', 'stance', 'pid', 'matchedDomain']).agg({
    'predictShared': 'mean', 'srgiResponse': 'mean',
    'experiment_num': 'first', 'stance_num': 'first'
}).reset_index()
```

```{python}
#| fig-cap: "Figure 2B: SR-G ~ Commonality"
#| fig-width: 9
#| fig-height: 4
g = sns.lmplot(data=srg_df, x='predictShared', y='srgiResponse',
               hue='stance', hue_order=['opposing', 'shared'],
               col='experiment', col_order=['no-chat', 'chat'],
               palette=lowhigh_palette, scatter_kws={'alpha': 0.3}, legend=False)
g.set_xlabels('Expected Commonality', fontweight='bold');
g.set_ylabels('SR-G', fontweight='bold');
g.set_titles('{col_name}');
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure2b_srg.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

```{python}
#| output: false
srg_df.to_csv('/tmp/srg_df.csv', index=False)
```

```{r}
srg_df <- read.csv('/tmp/srg_df.csv')
model <- lmer(srgiResponse ~ predictShared * experiment_num * stance_num + (1|matchedDomain),
              data = srg_df)
summary(model)
confint(model, method = "Wald")
```

## 5. Domain Analysis (Figure 3 + Domain-Specific Models)

Paper reports: 42 models (7 domains × 3 types × 2 stances), >95% positive coefficients, all significant effects positive after FDR (p.9)

```{python}
#| fig-cap: "Figure 3: Domain-level heatmaps"
#| fig-width: 10
#| fig-height: 10
# Reload modules and data
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
base_dir = Path.cwd().resolve()
while base_dir.name and not (base_dir / 'data').exists():
    base_dir = base_dir.parent
figures_dir = base_dir / 'outputs' / 'figures'
lowhigh_palette = ['#648FFF', '#DC267F']
SAVE_FIGURES = True  # Save figures when running
df_pd = pd.read_csv('/tmp/main_df.csv', low_memory=False)

domain_order = ['Lifestyle', 'Background', 'Identity', 'Morality', 'Politics', 'Preferences', 'Religion']
category_order = ['sameQ', 'sameD', 'diffD']
category_labels = ['Same\nQuestion', 'Same\nDomain', 'Different\nDomain']

df_pd['domain_cap'] = df_pd['matchedDomain'].str.replace('arbitrary', 'Lifestyle').str.capitalize()
heatmap_data = df_pd.groupby(['experiment', 'stance', 'domain_cap', 'category'])['predictShared'].mean().reset_index()

fig, axes = plt.subplots(3, 2, figsize=(10, 10), sharex=True)

for row, exp in enumerate(['chat', 'no-chat']):
    for col_idx, stance in enumerate(['opposing', 'shared']):
        ax = axes[row, col_idx]
        subset = heatmap_data[(heatmap_data['experiment'] == exp) & (heatmap_data['stance'] == stance)]
        pivot = subset.pivot(index='domain_cap', columns='category', values='predictShared')
        pivot = pivot.reindex(index=domain_order, columns=category_order)
        sns.heatmap(pivot, ax=ax, cmap='YlOrRd', vmin=0, vmax=1, cbar=(col_idx == 1),
                    cbar_kws={'label': '% Commonality'} if col_idx == 1 else {})
        ax.set_xticklabels(category_labels, rotation=45, ha='right')
        ax.set_ylabel('Domain' if col_idx == 0 else '')
        ax.set_xlabel('')
        if row == 0:
            ax.set_title(stance.capitalize(), fontweight='bold')

# Contrast row
for col_idx, stance in enumerate(['opposing', 'shared']):
    ax = axes[2, col_idx]
    chat = heatmap_data[(heatmap_data['experiment'] == 'chat') & (heatmap_data['stance'] == stance)]
    nochat = heatmap_data[(heatmap_data['experiment'] == 'no-chat') & (heatmap_data['stance'] == stance)]
    merged = chat.merge(nochat, on=['domain_cap', 'category'], suffixes=('_chat', '_nochat'))
    merged['diff'] = merged['predictShared_chat'] - merged['predictShared_nochat']
    pivot = merged.pivot(index='domain_cap', columns='category', values='diff')
    pivot = pivot.reindex(index=domain_order, columns=category_order)
    sns.heatmap(pivot, ax=ax, cmap='RdBu_r', center=0, vmin=-0.3, vmax=0.3, cbar=(col_idx == 1),
                cbar_kws={'label': 'Chat - No-Chat'} if col_idx == 1 else {})
    ax.set_xticklabels(category_labels, rotation=45, ha='right')
    ax.set_ylabel('Domain' if col_idx == 0 else '')

axes[0, 0].text(-0.3, 0.5, 'Chat', transform=axes[0, 0].transAxes, fontweight='bold', va='center', rotation=90)
axes[1, 0].text(-0.3, 0.5, 'No-Chat', transform=axes[1, 0].transAxes, fontweight='bold', va='center', rotation=90)
axes[2, 0].text(-0.3, 0.5, 'Contrast', transform=axes[2, 0].transAxes, fontweight='bold', va='center', rotation=90)

plt.tight_layout()
if SAVE_FIGURES:
    plt.savefig(figures_dir / 'figure3_heatmaps.pdf', dpi=300, bbox_inches='tight')
plt.show()
```

### 42 Domain-Specific Models

```{r}
domain_df <- read.csv('/tmp/main_df.csv')
domain_df$experiment <- factor(domain_df$experiment, levels = c('no-chat', 'chat'))
contrasts(domain_df$experiment) <- cbind(c(-0.5, 0.5))

fit_model <- function(data, cat) {
    if (cat == 'sameQ') {
        m <- glm(predictShared ~ experiment, data = data, family = binomial())
    } else {
        m <- glmer(predictShared ~ experiment + (1|pid), data = data, family = binomial(),
                   control = glmerControl(optimizer = 'bobyqa', optCtrl = list(maxfun = 100000)))
    }
    tibble(beta = coef(summary(m))[2, 1], pVal = coef(summary(m))[2, 4])
}

results <- domain_df %>%
    group_by(matchedDomain, category, stance) %>%
    nest() %>%
    mutate(res = map2(data, category, fit_model)) %>%
    select(-data) %>%
    unnest(res) %>%
    ungroup() %>%
    mutate(pVal_fdr = p.adjust(pVal, method = 'fdr'))

n_pos <- sum(results$beta > 0)
n_sig_pos <- sum(results$pVal_fdr < 0.05 & results$beta > 0)
n_sig_neg <- sum(results$pVal_fdr < 0.05 & results$beta < 0)

cat(sprintf('Total models: %d\n', nrow(results)))
cat(sprintf('Positive coefficients: %d (%.1f%%)\n', n_pos, 100 * n_pos / nrow(results)))
cat(sprintf('Significant after FDR: %d positive, %d negative\n', n_sig_pos, n_sig_neg))
cat('\nPaper reports: >95% positive, all significant effects positive\n')
```

## 6. Sample Description

```{python}
# Reload data
import pandas as pd
df_pd = pd.read_csv('/tmp/main_df.csv', low_memory=False)

print('=== Sample Description ===')
print(f"Total participants: N = {df_pd['pid'].nunique()}")
print(f"  No-chat: n = {df_pd[df_pd['experiment'] == 'no-chat']['pid'].nunique()}")
print(f"  Chat: n = {df_pd[df_pd['experiment'] == 'chat']['pid'].nunique()}")
print(f"  Chat dyads: {df_pd[df_pd['experiment'] == 'chat']['dyadId'].nunique()}")
print(f'\nPaper reports: N = 1,205 (527 imagined; 678 real, 339 dyads)')
```
